{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6faeff81-b5d7-4d06-a2bc-e55ed89ebe14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_train = pd.read_csv('master_data_train_final_scaled_with_ids.csv')\n",
    "data_test = pd.read_csv('master_data_test_final_scaled_with_ids.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1f70c86-b2f4-401c-80b0-2a11b7a2a103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names cleaned and datasets split successfully.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Replace invalid characters in feature names across the whole dataset\n",
    "data_train.columns = data_train.columns.str.replace('<', '_').str.replace('>', '_').str.replace(' ', '_')\n",
    "data_test.columns = data_test.columns.str.replace('<', '_').str.replace('>', '_').str.replace(' ', '_')\n",
    "\n",
    "# Now proceed with splitting\n",
    "X = data_train.drop(columns=['TARGET'])\n",
    "y = data_train['TARGET']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Feature names cleaned and datasets split successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d399f87f-a37b-4ce9-a741-4e03e3efab02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split into training and testing subsets.\n",
      "SMOTE applied to training data.\n",
      "Class Distribution After SMOTE:\n",
      "0.0    226132\n",
      "1.0    226132\n",
      "Name: TARGET, dtype: int64\n",
      "Model trained with SMOTE-balanced training data.\n",
      "\n",
      "Evaluation on Testing Subset:\n",
      "Test Accuracy: 0.9184267434108905\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      1.00      0.96     56554\n",
      "         1.0       0.38      0.02      0.04      4949\n",
      "\n",
      "    accuracy                           0.92     61503\n",
      "   macro avg       0.65      0.51      0.50     61503\n",
      "weighted avg       0.88      0.92      0.88     61503\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Step 1: Split the dataset into training and testing subsets\n",
    "X = data_train.drop(columns=['TARGET'])\n",
    "y = data_train['TARGET']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Data split into training and testing subsets.\")\n",
    "\n",
    "# Step 2: Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"SMOTE applied to training data.\")\n",
    "print(\"Class Distribution After SMOTE:\")\n",
    "print(y_train_smote.value_counts())\n",
    "\n",
    "# Step 3: Train the XGBoost model with the best hyperparameters\n",
    "xgb_model = XGBClassifier(\n",
    "    learning_rate=0.2,\n",
    "    max_depth=7,\n",
    "    n_estimators=200,\n",
    "    subsample=1.0,\n",
    "    random_state=42\n",
    ")\n",
    "xgb_model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "print(\"Model trained with SMOTE-balanced training data.\")\n",
    "\n",
    "# Step 4: Evaluate on the testing subset\n",
    "y_pred_test = xgb_model.predict(X_test)\n",
    "\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "report_test = classification_report(y_test, y_pred_test)\n",
    "\n",
    "print(\"\\nEvaluation on Testing Subset:\")\n",
    "print(\"Test Accuracy:\", accuracy_test)\n",
    "print(report_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "601d2c34-c283-4813-a67b-77afc52e1707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation on Training Subset:\n",
      "Train Accuracy: 0.9250146336704498\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      1.00      0.96    226132\n",
      "         1.0       0.91      0.08      0.15     19876\n",
      "\n",
      "    accuracy                           0.93    246008\n",
      "   macro avg       0.92      0.54      0.55    246008\n",
      "weighted avg       0.92      0.93      0.90    246008\n",
      "\n",
      "\n",
      "Evaluation on Testing Subset:\n",
      "Test Accuracy: 0.9184267434108905\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      1.00      0.96     56554\n",
      "         1.0       0.38      0.02      0.04      4949\n",
      "\n",
      "    accuracy                           0.92     61503\n",
      "   macro avg       0.65      0.51      0.50     61503\n",
      "weighted avg       0.88      0.92      0.88     61503\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Evaluate on the training subset\n",
    "y_pred_train = xgb_model.predict(X_train)\n",
    "\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "report_train = classification_report(y_train, y_pred_train)\n",
    "\n",
    "print(\"\\nEvaluation on Training Subset:\")\n",
    "print(\"Train Accuracy:\", accuracy_train)\n",
    "print(report_train)\n",
    "\n",
    "# Evaluate on the testing subset\n",
    "y_pred_test = xgb_model.predict(X_test)\n",
    "\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "report_test = classification_report(y_test, y_pred_test)\n",
    "\n",
    "print(\"\\nEvaluation on Testing Subset:\")\n",
    "print(\"Test Accuracy:\", accuracy_test)\n",
    "print(report_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f75b8a22-2731-4a75-8d8f-b51618d87cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Evaluation on Training Subset:\n",
      "Train Accuracy: 0.5569940814932848\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.56      0.70    226132\n",
      "         1.0       0.09      0.48      0.15     19876\n",
      "\n",
      "    accuracy                           0.56    246008\n",
      "   macro avg       0.51      0.52      0.42    246008\n",
      "weighted avg       0.86      0.56      0.66    246008\n",
      "\n",
      "\n",
      "Logistic Regression Evaluation on Testing Subset:\n",
      "Test Accuracy: 0.5543469424255727\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.56      0.70     56554\n",
      "         1.0       0.09      0.47      0.15      4949\n",
      "\n",
      "    accuracy                           0.55     61503\n",
      "   macro avg       0.51      0.52      0.42     61503\n",
      "weighted avg       0.86      0.55      0.65     61503\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Step 1: Train the Logistic Regression model\n",
    "logistic_model = LogisticRegression(penalty='l2', C=1.0, solver='lbfgs', max_iter=1000, random_state=42)\n",
    "logistic_model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Step 2: Evaluate on the training subset\n",
    "y_pred_train_log = logistic_model.predict(X_train)\n",
    "accuracy_train_log = accuracy_score(y_train, y_pred_train_log)\n",
    "report_train_log = classification_report(y_train, y_pred_train_log)\n",
    "\n",
    "print(\"\\nLogistic Regression Evaluation on Training Subset:\")\n",
    "print(\"Train Accuracy:\", accuracy_train_log)\n",
    "print(report_train_log)\n",
    "\n",
    "# Step 3: Evaluate on the testing subset\n",
    "y_pred_test_log = logistic_model.predict(X_test)\n",
    "accuracy_test_log = accuracy_score(y_test, y_pred_test_log)\n",
    "report_test_log = classification_report(y_test, y_pred_test_log)\n",
    "\n",
    "print(\"\\nLogistic Regression Evaluation on Testing Subset:\")\n",
    "print(\"Test Accuracy:\", accuracy_test_log)\n",
    "print(report_test_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0c67e99-23c9-4574-ac26-73b5f1a3b9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = xgb_model.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fb15b1f-8989-4611-8106-615957f4f927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for the test data:\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "Total predictions: 48744\n"
     ]
    }
   ],
   "source": [
    "# Check predictions\n",
    "print(\"Predictions for the test data:\")\n",
    "print(Y_test[:10])  # Show the first 10 predictions\n",
    "print(f\"Total predictions: {len(Y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c148bacf-bbe6-42a6-8289-c9a787ea05c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved as 'final_predictions.csv'\n"
     ]
    }
   ],
   "source": [
    "# Combine predictions with SK_ID_CURR\n",
    "submission = pd.DataFrame({\n",
    "    'SK_ID_CURR': data_test['SK_ID_CURR'],\n",
    "    'TARGET': Y_test\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "submission.to_csv('final_predictions.csv', index=False)\n",
    "\n",
    "print(\"Predictions saved as 'final_predictions.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce1163d-fcc3-42aa-ab3d-e6026b0c55c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
